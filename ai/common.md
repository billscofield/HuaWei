# basic of ai

mse
    mean 平均
    s 平方
    e 误差

Linear Regression

## 人工智能，机器学习和深度学习

## 基本工作流程

数据基本处理 -> 特征工程 -> 机器学习 -> 模型评估
   /|\                                     \|/
    |                                       |
    +---------------------<-----------------+

样本
特征
特征值
目标

### 算法分类

监督学习
    有特征值，有目标值
    分类
    回归
无监督学习
    只有特征值，无目标值
    聚类
半监督学习
强化学习





## 请以一元一次方程为例解释，在 Rosenblatt 的感知器算法中，为什么误差 要乘以 输入x

在 Rosenblatt 的感知器算法中，我们希望通过迭代来训练模型，使其能够正确地分类数
据。为了实现这一点，我们需要不断地调整模型的权重，以便它能够更好地拟合数据。

对于一个二元分类问题，感知器算法试图找到一个超平面（在二维空间中就是一条直线），
将不同类别的数据点分开。我们可以用一个线性函数来表示这个超平面，即：

    `y = w * x + b`

其中，w 是权重，b 是偏差（或截距），x 是输入数据，y 是输出结果。为了训练模型，
我们需要不断地调整 w 和 b 的值，以便模型能够更好地拟合数据。具体来说，我们希望
使模型的预测结果与真实结果之间的误差最小化。

在 Rosenblatt 的感知器算法中，误差计算方式是真实结果与模型预测结果之间的差值，
即:

    `error = label - output`

其中，label 是真实结果，output 是模型的预测结果。

我们可以将误差看作一个衡量模型表现的指标。如果误差很大，说明模型的预测效果很差，
需要进行调整。反之，如果误差很小，说明模型的预测效果很好，可以继续使用。

为了调整权重 w，我们需要根据误差的大小来改变它的值。具体来说，如果误差很大，我
们需要增加权重，以便模型更好地拟合数据。如果误差很小，我们需要减少权重，以免模
型过度拟合数据。而对于偏差 b，我们可以采用相同的方法来调整它的值。

在 Rosenblatt 的感知器算法中，我们可以通过以下公式来更新权重 w：

    `w' = w + learning_rate * error * x`

其中，w' 是更新后的权重，learning_rate 是学习率，error 是误差，x 是输入数据。学
习率是一个超参数，用来控制每次迭代时权重的调整幅度。**误差乘以输入数据 x 的作用
是调整权重的方向和大小，从而使误差逐渐减小**。

因此，为了更新权重，我们需要将误差乘以输入数据 x。这样，误差越大，权重的调整量就越大；误差越小，权重的调整量就越小。这样可以让模型更快地收敛到最优解，从而提高训练

### 不乘以 `x` 不也一样吗？

在Rosenblatt的感知器算法中，如果我们不将误差乘以输入x，那么更新权重w的时候，所
有的权重更新值都是一样的，因为所有的输入特征都是相同的（如果不考虑截距项）。这
样就无法区分哪些特征对预测的影响更大，哪些对影响更小，无法进行权重的有针对性调
整，导致模型的泛化能力不足，不能很好地适应新的数据。所以将误差乘以输入x可以使权
重更新值的大小不同，有针对性地调整权重，从而提高模型的泛化能力

### 那如果以一元一次方程为例, x 会越来越大，那不是说明后边的值的影响更大？

在感知器算法中，对于每个输入特征，我们都有一个权重 `w`，它代表了这个特征对结果
的影响力。在误差的计算中，我们希望将误差分配到每个特征上，以便调整相应的权重，
从而让模型更好地拟合数据。误差乘以输入特征 `x` 的目的就是将误差分配到相应的特征
上，并且根据 `x` 的大小来调整相应的权重。

如果不乘以 `x`，那么每个特征的权重就无法得到针对性的调整，模型就会变得比较笨拙，
不能充分利用每个特征对结果的影响。

虽然在一元一次方程中，`x` 的值确实会越来越大，但是在多个特征的情况下，**每个特征
对结果的影响并不是单调递增的，可能存在某些特征对结果的影响比其他特征更大**，因此
我们需要针对每个特征进行调整，使得权重能够充分反映其对结果的影响。

假设我们有一个简单的一元一次方程 `y = wx + b`，其中 `w` 和 `b` 是我们需要学习的
权重和偏置，`x` 是输入，`y` 是输出。在 Rosenblatt 的感知器算法中，我们的目标是
让感知器学会给出正确的输出。

为了实现这个目标，我们需要根据实际输出和期望输出之间的误差来更新权重和偏置。当
误差为正时，我们需要增加权重和偏置的值，使输出更接近期望输出；当误差为负时，我
们需要减小权重和偏置的值，使输出更接近期望输出。

那么，为什么我们要将误差乘以输入 x 呢？这是因为我们希望更多地更新对模型偏离期望
输出更有贡献的输入。如果我们没有将误差乘以输入，那么我们对所有输入的权重更新将
是相等的，无法区分哪些输入对误差的贡献更大。

例如，如果我们的输入是身高和体重，并且我们的目标是根据身高和体重预测一个人的健
康状况。如果我们没有将误差乘以身高和体重，那么我们对身高和体重的权重更新将是相
等的。然而，身高可能对预测健康状况的贡献更大，因此我们希望更多地更新身高的权重，
以使模型更准确地预测健康状况。

因此，在 Rosenblatt 的感知器算法中，我们将误差乘以输入 x，以使我们更多地更新对
误差有更大贡献的输入。


